import os
import os.path as osp
import torch
from torch.utils.data import Dataset, random_split

# é…ç½®è·¯å¾„ (æ ¹æ®ä½ çš„ arg_util.py)
DATA_PATH = '/home/OmniStyle-150K'
OUTPUT_DIR = './split_info'  # è¾“å‡ºç»“æœä¿å­˜çš„æ–‡ä»¶å¤¹

class FilenameDataset(Dataset):
    """
    è¿™æ˜¯ä¸€ä¸ªè½»é‡çº§çš„ Dataset ç±»ï¼Œåªè´Ÿè´£è¯»å–æ–‡ä»¶åï¼Œä¸è¯»å–å›¾ç‰‡æ•°æ®ã€‚
    é€»è¾‘ä¸¥æ ¼å¤åˆ» utils/data.py ä¸­çš„ StyleTransferDatasetã€‚
    """
    def __init__(self, root_dir):
        self.root_dir = root_dir
        self.target_dir = osp.join(root_dir, 'target')
        
        if not os.path.exists(self.target_dir):
            raise FileNotFoundError(f"Target directory not found: {self.target_dir}")

        # --- ä¸¥æ ¼å¤åˆ» data.py çš„æ‰«æé€»è¾‘ ---
        # åŸä»£ç : self.target_files = [f for f in os.listdir(self.target_dir) if '&&' in f]
        # æ³¨æ„ï¼šos.listdir çš„é¡ºåºå–å†³äºæ–‡ä»¶ç³»ç»Ÿï¼Œä½†åœ¨åŒä¸€å°æœºå™¨æœªå˜åŠ¨æ–‡ä»¶çš„æƒ…å†µä¸‹é€šå¸¸æ˜¯ç¨³å®šçš„ã€‚
        # å¦‚æœä¸ºäº†ç»å¯¹ä¸¥è°¨ï¼ŒåŸ data.py åº”è¯¥åŠ ä¸Š sorted()ï¼Œä½†ä¸ºäº†å¤ç°ä½ ç°åœ¨çš„çŠ¶æ€ï¼Œè¿™é‡Œå¿…é¡»ä¿æŒåŸæ ·ä¸åŠ  sortã€‚
        self.target_files = [f for f in os.listdir(self.target_dir) if '&&' in f]
        
    def __len__(self):
        return len(self.target_files)
    
    def __getitem__(self, idx):
        # åªè¿”å›æ–‡ä»¶å
        return self.target_files[idx]

def export_splits():
    print(f"ğŸ” Scanning directory: {DATA_PATH} ...")
    
    # 1. åˆå§‹åŒ–æ•°æ®é›†
    full_dataset = FilenameDataset(DATA_PATH)
    total_len = len(full_dataset)
    
    if total_len == 0:
        print("âŒ Error: No files found!")
        return

    # 2. å¤åˆ»åˆ’åˆ†é€»è¾‘ (Copy from utils/data.py)
    val_len = int(total_len * 0.05)
    train_len = total_len - val_len
    
    print(f"ğŸ“Š Total files: {total_len}")
    print(f"   Training set size:   {train_len}")
    print(f"   Validation set size: {val_len}")
    print(f"   Random Seed:         42")

    # 3. æ‰§è¡Œéšæœºåˆ’åˆ†
    # è¿™é‡Œå¿…é¡»ä½¿ç”¨å’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€æ ·çš„ Generator å’Œ Seed
    train_subset, val_subset = random_split(
        full_dataset, 
        [train_len, val_len], 
        generator=torch.Generator().manual_seed(42)
    )
    
    # 4. ä¿å­˜æ–‡ä»¶åˆ—è¡¨
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    def save_to_file(subset, fname):
        output_path = os.path.join(OUTPUT_DIR, fname)
        print(f"ğŸ’¾ Saving {fname} ...", end="")
        with open(output_path, 'w', encoding='utf-8') as f:
            # subset.indices åŒ…å«äº†éšæœºåˆ’åˆ†åçš„ç´¢å¼•åˆ—è¡¨
            for idx in subset.indices:
                # é€šè¿‡ç´¢å¼•å»åŸå§‹æ•°æ®é›†ä¸­æ‹¿æ–‡ä»¶å
                filename = full_dataset.target_files[idx]
                f.write(filename + '\n')
        print(f" Done! Saved to {output_path}")

    save_to_file(train_subset, "train_files.txt")
    save_to_file(val_subset, "val_files.txt")
    
    print("\nâœ… All done.")

if __name__ == '__main__':
    export_splits()